{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierre-Elliott THIBOUD  \n",
    "Julien PERIER-CAMBY  \n",
    "\n",
    "# IBI - TP1\n",
    "## Partie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip # pour décompresser les données\n",
    "import pickle # pour désérialiser les données\n",
    "import numpy as np # pour pouvoir utiliser des matrices\n",
    "import matplotlib.pyplot as plt # pour l'affichage\n",
    "import torch,torch.utils.data\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affichage(image,label):\n",
    "    # on récupère à quel chiffre cela correspond (position du 1 dans label)\n",
    "    label = np.argmax(label)\n",
    "    # on crée une figure\n",
    "    plt.figure()\n",
    "    # affichage du chiffre\n",
    "    # le paramètre interpolation='nearest' force python à afficher chaque valeur de la matrice sans l'interpoler avec ses voisines\n",
    "    # le paramètre cmap définit l'échelle de couleur utilisée (ici noire et blanc)\n",
    "    plt.imshow(image.reshape((28,28)),interpolation='nearest',cmap='binary')\n",
    "    # on met un titre\n",
    "    plt.title('chiffre '+str(label))\n",
    "    # on affichage les figures créées\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 1\n",
    "\n",
    "data = pickle.load(gzip.open('mnist.pkl.gz'),encoding='latin1')\n",
    "\n",
    "train_data = torch.Tensor(data[0][0])\n",
    "# labels de la base d'apprentissage\n",
    "train_data_label = torch.Tensor(data[0][1])\n",
    "# images de la base de test\n",
    "test_data = torch.Tensor(data[1][0])\n",
    "# labels de la base de test\n",
    "test_data_label = torch.Tensor(data[1][1])\n",
    "# on crée la base de données d'apprentissage (pour torch)\n",
    "train_dataset = torch.utils.data.TensorDataset(train_data,train_data_label)\n",
    "# on crée la base de données de test (pour torch)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_data,test_data_label)\n",
    "# on crée le lecteur de la base de données d'apprentissage (pour torch)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "# on crée le lecteur de la base de données de test (pour torch)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "affichage(train_data[0], train_data_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "nb_class = 10\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, nb_class, input_dim):\n",
    "        self.weights = np.random.normal(loc=0.0,scale=1.0,size=(nb_class,input_dim+1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Return output\n",
    "        #print(x)\n",
    "        x = np.append(x.flatten(),1)\n",
    "#         print(x.size())\n",
    "        return np.dot(self.weights, x)\n",
    "\n",
    "    def backward(self, x, y, t):\n",
    "        error = t - y\n",
    "        # Rajoute le biais\n",
    "        x = np.append(x.flatten(), 1)\n",
    "        \n",
    "        # passe de x(785,) à x(785, 10)\n",
    "        x = np.repeat(x[:, np.newaxis], 10, axis=1)\n",
    "        delta = error * x * learning_rate\n",
    "        \n",
    "        # Mise à jour des poids\n",
    "        self.weights *= delta.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0960908edd4b1186e06ec327b99e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=4, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684bb33dd61d458a8de683e7329859fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-e9a60296aee1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-76-e9a60296aee1>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;31m# on demande les prochaines données de la base\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-24bce14b227a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m# Return output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m#print(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#         print(x.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Perceptron(nb_class, input_dim)\n",
    "\n",
    "def training():\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "        for (_,(image,label)) in enumerate(train_loader):\n",
    "            # on demande les prochaines données de la base\n",
    "            y = model.forward(image)\n",
    "            model.backward(image.numpy(), y, label.numpy())\n",
    "            \n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000ad469d28742c38f3c25c697d93aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.09785714285714285\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    true_positives = 0\n",
    "    for (_,(image,label)) in enumerate(tqdm(test_loader)):\n",
    "        y = model.forward(image)\n",
    "        if np.argmax(label.numpy()) == np.argmax(y):\n",
    "            true_positives += 1\n",
    "    print(\"Accuracy: \", true_positives/len(test_loader))\n",
    "    \n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
