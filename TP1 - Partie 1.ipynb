{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierre-Elliott THIBOUD  \n",
    "Julien PERIER-CAMBY  \n",
    "\n",
    "# IBI - TP1\n",
    "## Partie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip # pour décompresser les données\n",
    "import pickle # pour désérialiser les données\n",
    "import numpy as np # pour pouvoir utiliser des matrices\n",
    "import matplotlib.pyplot as plt # pour l'affichage\n",
    "import torch,torch.utils.data\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affichage(image,label):\n",
    "    # on récupère à quel chiffre cela correspond (position du 1 dans label)\n",
    "    label = np.argmax(label)\n",
    "    # on crée une figure\n",
    "    plt.figure()\n",
    "    # affichage du chiffre\n",
    "    # le paramètre interpolation='nearest' force python à afficher chaque valeur de la matrice sans l'interpoler avec ses voisines\n",
    "    # le paramètre cmap définit l'échelle de couleur utilisée (ici noire et blanc)\n",
    "    plt.imshow(image.reshape((28,28)),interpolation='nearest',cmap='binary')\n",
    "    # on met un titre\n",
    "    plt.title('chiffre '+str(label))\n",
    "    # on affichage les figures créées\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 1\n",
    "\n",
    "data = pickle.load(gzip.open('mnist.pkl.gz'),encoding='latin1')\n",
    "\n",
    "train_data = torch.Tensor(data[0][0])\n",
    "# labels de la base d'apprentissage\n",
    "train_data_label = torch.Tensor(data[0][1])\n",
    "# images de la base de test\n",
    "test_data = torch.Tensor(data[1][0])\n",
    "# labels de la base de test\n",
    "test_data_label = torch.Tensor(data[1][1])\n",
    "# on crée la base de données d'apprentissage (pour torch)\n",
    "train_dataset = torch.utils.data.TensorDataset(train_data,train_data_label)\n",
    "# on crée la base de données de test (pour torch)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_data,test_data_label)\n",
    "# on crée le lecteur de la base de données d'apprentissage (pour torch)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "# on crée le lecteur de la base de données de test (pour torch)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "affichage(train_data[0], train_data_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "nb_class = 10\n",
    "\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, input_dim, output_dim, learning_rate):\n",
    "        self.weights = np.random.normal(loc=0.0,scale=1.0,size=(output_dim,input_dim+1))\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Return output\n",
    "        x = np.append(x.flatten(),1)\n",
    "        return np.dot(self.weights, x)\n",
    "\n",
    "    def backward(self, x, y, t):\n",
    "        error = np.array(t) - y\n",
    "        # Rajoute le biais\n",
    "        x = np.append(np.array(x).flatten(), 1)\n",
    "        \n",
    "        delta = x.reshape(785,1).dot(error.reshape(1,10)) * self.learning_rate\n",
    "        \n",
    "        # Mise à jour des poids\n",
    "        self.weights += delta.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Perceptron(input_dim, nb_class,; learning_rate)\n",
    "\n",
    "def training(model, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for (idx,(image,label)) in enumerate(train_loader):\n",
    "            # on demande les prochaines données de la base\n",
    "            y = model.forward(image)\n",
    "            model.backward(image, y, label)\n",
    "            \n",
    "training(model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.521\n"
     ]
    }
   ],
   "source": [
    "def test(model):\n",
    "    true_positives = 0\n",
    "    for (idx,(image,label)) in enumerate(test_loader):\n",
    "        if np.argmax(label.numpy()) == np.argmax(model.forward(image)):\n",
    "            true_positives += 1\n",
    "    print(\"Accuracy: \", true_positives/len(test_loader))\n",
    "    \n",
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "Learning rate : 0.001\n",
      "Epoch 5 :Accuracy:  0.6071428571428571\n",
      "Epoch 10 :Accuracy:  0.7398571428571429\n",
      "Epoch 15 :Accuracy:  0.7882857142857143\n",
      "Epoch 20 :Accuracy:  0.8074285714285714\n",
      "Epoch 25 :Accuracy:  0.8171428571428572\n",
      "------------------\n",
      "Learning rate : 0.01\n",
      "Epoch 5 :Accuracy:  0.693\n",
      "Epoch 10 :Accuracy:  0.7001428571428572\n",
      "Epoch 15 :Accuracy:  0.6814285714285714\n",
      "Epoch 20 :Accuracy:  0.6928571428571428\n",
      "Epoch 25 :Accuracy:  0.6978571428571428\n",
      "------------------\n",
      "Learning rate : 0.1\n",
      "Epoch 5 :Accuracy:  0.09785714285714285\n",
      "Epoch 10 :Accuracy:  0.09785714285714285\n",
      "Epoch 15 :Accuracy:  0.09785714285714285\n",
      "Epoch 20 :Accuracy:  0.09785714285714285\n",
      "Epoch 25 :Accuracy:  0.09785714285714285\n"
     ]
    }
   ],
   "source": [
    "learning_rates = (1e-3, 1e-2, 0.1)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(\"------------------\\nLearning rate :\", lr)\n",
    "    model = Perceptron(nb_class, input_dim, lr)\n",
    "    \n",
    "    for k in range(1,6):\n",
    "        training(model, 5)\n",
    "        print(\"Epoch\", k*5, \": \", end='')\n",
    "        test(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Nerwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, nb_class, input_dim, nb_neurons):\n",
    "        self.hidden_layer = Perceptron(input_dim, nb_neurons)\n",
    "        self.output_layer = Perceptron(nb_neurons, nb_class)\n",
    "        self.hidden_output = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        yi = self.hidden_layer.forward(x)\n",
    "        self.hidden_output = 1/(1 + np.exp(-np.sum(yi)))\n",
    "            \n",
    "        return self.output_layer.forward(self.hidden_output)\n",
    "    \n",
    "    def backward(self, x, y ,t):\n",
    "        output_error = np.array(t) - y\n",
    "        self.hidden_output*(1-self.hidden_output)*np.sum(self.output_layer.weights.dot())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
